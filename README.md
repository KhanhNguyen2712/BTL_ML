# üöó German Used Car Price Prediction

[![Python](https://img.shields.io/badge/Python-3.12-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-latest-orange.svg)](https://scikit-learn.org/)
[![XGBoost](https://img.shields.io/badge/XGBoost-latest-red.svg)](https://xgboost.readthedocs.io/)

B√†i t·∫≠p l·ªõn Machine Learning d·ª± ƒëo√°n gi√° xe c≈© t·∫°i th·ªã tr∆∞·ªùng ƒê·ª©c s·ª≠ d·ª•ng c√°c thu·∫≠t to√°n Regression. D·ª± √°n so s√°nh 6 m√¥ h√¨nh ML kh√°c nhau v√† th·ª±c hi·ªán hyperparameter tuning ƒë·ªÉ ƒë·∫°t ƒë∆∞·ª£c hi·ªáu su·∫•t t·ªët nh·∫•t.

---

## üìã M·ª•c l·ª•c

- [Gi·ªõi thi·ªáu](#-gi·ªõi-thi·ªáu)
- [Dataset](#-dataset)
- [C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng](#Ô∏è-c√†i-ƒë·∫∑t-m√¥i-tr∆∞·ªùng)
- [C·∫•u tr√∫c th∆∞ m·ª•c](#-c·∫•u-tr√∫c-th∆∞-m·ª•c)
- [H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng](#-h∆∞·ªõng-d·∫´n-s·ª≠-d·ª•ng)
- [Quy tr√¨nh th·ª±c hi·ªán](#-quy-tr√¨nh-th·ª±c-hi·ªán)
- [K·∫øt qu·∫£](#-k·∫øt-qu·∫£)
- [C√¥ng ngh·ªá s·ª≠ d·ª•ng](#-c√¥ng-ngh·ªá-s·ª≠-d·ª•ng)
- [L∆∞u √Ω quan tr·ªçng](#-l∆∞u-√Ω-quan-tr·ªçng)
- [T√°c gi·∫£](#-t√°c-gi·∫£)

---

## üéØ Gi·ªõi thi·ªáu

B√†i t·∫≠p l·ªõn n√†y x√¢y d·ª±ng m√¥ h√¨nh Machine Learning ƒë·ªÉ d·ª± ƒëo√°n gi√° xe c≈© t·∫°i th·ªã tr∆∞·ªùng ƒê·ª©c d·ª±a tr√™n c√°c ƒë·∫∑c ƒëi·ªÉm k·ªπ thu·∫≠t v√† th√¥ng tin xe. M·ª•c ti√™u l√† t√¨m ra m√¥ h√¨nh c√≥ ƒë·ªô ch√≠nh x√°c cao nh·∫•t v√† hi·ªÉu ƒë∆∞·ª£c c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn gi√° xe.

## üéØ M·ª•c ti√™u ch√≠nh:

- Ph√¢n t√≠ch v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu xe c≈© t·ª´ th·ªã tr∆∞·ªùng ƒê·ª©c
- So s√°nh hi·ªáu su·∫•t c·ªßa 6 m√¥ h√¨nh ML: XGBoost, Random Forest, Gradient Boosting, Decision Tree, Linear Regression, KNN
- T·ªëi ∆∞u h√≥a hyperparameters cho 2 m√¥ h√¨nh: KNN v√† Random Forest
- ƒê·∫°t ƒë∆∞·ª£c R¬≤ score > 0.80 tr√™n t·∫≠p test

---

## üìä Dataset

### Th√¥ng tin chung

- **T√™n dataset**: German Used Car Dataset (`autos.csv`)
- **S·ªë l∆∞·ª£ng records**: 371,528 xe
- **S·ªë l∆∞·ª£ng features**: 20 c·ªôt
- **K√≠ch th∆∞·ªõc**: ~56.7 MB
- **Target variable**: `price` (Gi√° xe, ƒë∆°n v·ªã ‚Ç¨)
- **Ngu·ªìn**: [Kaggle - Used Cars Dataset](https://www.kaggle.com/datasets/thedevastator/uncovering-factors-that-affect-used-car-prices/data)
### C√°c features ch√≠nh

| Feature               | Ki·ªÉu d·ªØ li·ªáu | M√¥ t·∫£                           |
| --------------------- | ------------ | ------------------------------- |
| `dateCrawled`         | Date         | Ng√†y thu th·∫≠p d·ªØ li·ªáu           |
| `name`                | String       | T√™n xe                          |
| `seller`              | String       | Lo·∫°i ng∆∞·ªùi b√°n (private/dealer) |
| `offerType`           | String       | Lo·∫°i rao b√°n                    |
| `price`               | Integer      | **Gi√° xe (Target)**             |
| `abtest`              | String       | A/B testing group               |
| `vehicleType`         | String       | Lo·∫°i xe (SUV, sedan, v.v.)      |
| `yearOfRegistration`  | Integer      | NƒÉm ƒëƒÉng k√Ω xe                  |
| `gearbox`             | String       | Lo·∫°i h·ªôp s·ªë (manual/automatic)  |
| `powerPS`             | Integer      | C√¥ng su·∫•t ƒë·ªông c∆° (PS)          |
| `model`               | String       | Model xe                        |
| `kilometer`           | Integer      | S·ªë km ƒë√£ ƒëi                     |
| `monthOfRegistration` | Integer      | Th√°ng ƒëƒÉng k√Ω                   |
| `fuelType`            | String       | Lo·∫°i nhi√™n li·ªáu                 |
| `brand`               | String       | H√£ng xe                         |
| `notRepairedDamage`   | String       | T√¨nh tr·∫°ng h∆∞ h·ªèng              |
| `dateCreated`         | Date         | Ng√†y t·∫°o qu·∫£ng c√°o              |
| `nrOfPictures`        | Integer      | S·ªë l∆∞·ª£ng h√¨nh ·∫£nh               |
| `postalCode`          | Integer      | M√£ b∆∞u ƒëi·ªán                     |
| `lastSeen`            | Date         | L·∫ßn cu·ªëi th·∫•y qu·∫£ng c√°o         |

### V·∫•n ƒë·ªÅ trong d·ªØ li·ªáu

- ‚ùå **Missing values**: 2.5% (184,008 cells)
  - `notRepairedDamage`: 19.4%
  - `vehicleType`: 10.2%
  - `fuelType`: 9.0%
- ‚ùå **Zero values**:
  - `price`: 10,778 (2.9%)
  - `powerPS`: 40,820 (11.0%)
- ‚ùå **Outliers**: Skewness cao trong `price` (gamma_1 = 578.06)
- ‚ùå **Duplicates**: 4 rows
- ‚ùå **High cardinality**: `brand` (40 unique), `model` (240+ unique)

---

## ‚öôÔ∏è C√†i ƒë·∫∑t m√¥i tr∆∞·ªùng

### Y√™u c·∫ßu h·ªá th·ªëng

- **Python**: 3.12+
- **RAM**: T·ªëi thi·ªÉu 8GB (khuy·∫øn ngh·ªã 16GB)
- **Disk space**: T·ªëi thi·ªÉu 500MB
- **OS**: Windows/Linux/MacOS

### Ph∆∞∆°ng ph√°p 1: S·ª≠ d·ª•ng Conda (Khuy·∫øn ngh·ªã)

```bash
# 1. Clone repository (n·∫øu c√≥)
git clone https://github.com/KhanhNguyen2712/BTL_ML.git

# 2. T·∫°o m√¥i tr∆∞·ªùng conda t·ª´ file environments.yml
conda env create -f environments.yml

# 3. K√≠ch ho·∫°t m√¥i tr∆∞·ªùng
conda activate ml_btl

# 4. Ki·ªÉm tra c√†i ƒë·∫∑t
python --version
jupyter --version
```

### Ph∆∞∆°ng ph√°p 2: S·ª≠ d·ª•ng pip + venv

```bash
# 1. T·∫°o virtual environment
python -m venv venv

# 2. K√≠ch ho·∫°t virtual environment
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 3. C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán
pip install -r requirements.txt

# 4. Ki·ªÉm tra c√†i ƒë·∫∑t
pip list
```

### C√°c th∆∞ vi·ªán ch√≠nh

```
numpy                 # T√≠nh to√°n s·ªë h·ªçc
pandas                # X·ª≠ l√Ω d·ªØ li·ªáu
matplotlib            # Visualization
seaborn               # Statistical visualization
scikit-learn          # Machine Learning framework
xgboost               # Gradient Boosting
ydata-profiling       # Automated EDA
category_encoders     # Target Encoding
tqdm                  # Progress bar
jupyter               # Notebook environment
```

---

## üìÅ C·∫•u tr√∫c th∆∞ m·ª•c

```
BTL/
‚îÇ
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ autos.csv              # Dataset ch√≠nh (371,528 rows)
‚îÇ   ‚îî‚îÄ‚îÄ data_desc.md           # M√¥ t·∫£ chi ti·∫øt dataset
‚îÇ
‚îú‚îÄ‚îÄ price_prediction.ipynb     # Notebook ch√≠nh (code g·ªëc)
‚îú‚îÄ‚îÄ requirements.txt           # Dependencies cho pip
‚îú‚îÄ‚îÄ environments.yml           # Environment config cho conda
‚îÇ
‚îî‚îÄ‚îÄ README.md                  # M√¥ t·∫£ cho to√†n b·ªô b√†i t·∫≠p l·ªõn
```

---

## üöÄ H∆∞·ªõng d·∫´n ch·∫°y

### 1. Chu·∫©n b·ªã d·ªØ li·ªáu

```bash
# ƒê·∫£m b·∫£o file autos.csv n·∫±m trong th∆∞ m·ª•c data/
ls data/autos.csv
```

### 2. Kh·ªüi ƒë·ªông Jupyter Notebook

```bash
# K√≠ch ho·∫°t m√¥i tr∆∞·ªùng (n·∫øu ch∆∞a)
conda activate ml_btl

# Kh·ªüi ƒë·ªông Jupyter
jupyter notebook
```

### 3. Ch·∫°y notebook

1. M·ªü file `price_prediction.ipynb`
2. Ch·∫°y t·ª´ng cell theo th·ª© t·ª± t·ª´ tr√™n xu·ªëng d∆∞·ªõi


---

## üî¨ Quy tr√¨nh th·ª±c hi·ªán

### 1Ô∏è‚É£ **Exploratory Data Analysis (EDA)**

- Load dataset t·ª´ `data/autos.csv`
- Ki·ªÉm tra th√¥ng tin c∆° b·∫£n: shape, dtypes, missing values
- T·∫°o b√°o c√°o t·ª± ƒë·ªông v·ªõi `ydata_profiling`
- Ph√¢n t√≠ch correlation, distribution, outliers

### 2Ô∏è‚É£ **Data Preprocessing**

#### B∆∞·ªõc 1: Basic Cleaning

```python
# Convert datetime columns
df["dateCrawled"] = pd.to_datetime(df["dateCrawled"])

# Remove duplicates
df.drop_duplicates(inplace=True)

# Drop useless columns
df.drop(columns=["nrOfPictures", "seller", "offerType"], inplace=True)
```

#### B∆∞·ªõc 2: Translation (German ‚Üí English)

- D·ªãch `gearbox`: manuell ‚Üí Manual, automatik ‚Üí Automatic
- D·ªãch `fuelType`: benzin ‚Üí Petrol, diesel ‚Üí Diesel
- D·ªãch `vehicleType`: kleinwagen ‚Üí Small Car, v.v.
- Standardize `brand` names

#### B∆∞·ªõc 3: Outlier Removal (IQR Method)

```python
# Remove outliers cho price, powerPS, yearOfRegistration
Q1 = df[column].quantile(0.25)
Q3 = df[column].quantile(0.75)
IQR = Q3 - Q1
bounds = [Q1 - 1.5*IQR, Q3 + 1.5*IQR]
```

#### B∆∞·ªõc 4: Missing Values & Feature Selection

- Drop rows v·ªõi missing values trong critical features
- X√≥a features c√≥ correlation th·∫•p v·ªõi `price`
- Drop datetime columns (kh√¥ng c·∫ßn cho prediction)

### 3Ô∏è‚É£ **Feature Engineering**

```python
# Numerical features: StandardScaler
numerical_features = ['yearOfRegistration', 'powerPS', 'kilometer']

# Low cardinality: OneHotEncoder
categorical_low = ['vehicleType', 'fuelType', 'gearbox', 'notRepairedDamage']

# High cardinality: TargetEncoder
categorical_high = ['brand', 'model']
```

### 4Ô∏è‚É£ **Model Training & Evaluation**

**6 m√¥ h√¨nh ƒë∆∞·ª£c so s√°nh:**

1. ‚úÖ XGBoost Regressor
2. ‚úÖ Random Forest Regressor
3. ‚úÖ Gradient Boosting Regressor
4. ‚úÖ Decision Tree Regressor
5. ‚úÖ Linear Regression
6. ‚úÖ K-Nearest Neighbors

**Evaluation strategy:**

- **K-Fold Cross-Validation** (k=5)
- **Metrics**: MAE, RMSE, R¬≤
- **Scoring**: Train & Test scores ƒë·ªÉ ph√°t hi·ªán overfitting

### 5Ô∏è‚É£ **Hyperparameter Tuning**

#### KNN (GridSearchCV)

```python
param_grid = {
    'n_neighbors': [3, 5],
    'weights': ['uniform', 'distance'],
    'p': [1, 2]  # Manhattan vs Euclidean
}
```

#### Random Forest (RandomizedSearchCV)

```python
param_dist = {
    'n_estimators': [100, 200],
    'max_depth': [10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}
```

### 6Ô∏è‚É£ **Final Testing**

- Train/Test split (80/20)
- Train m√¥ h√¨nh v·ªõi best parameters
- ƒê√°nh gi√° tr√™n test set

---

## üìà K·∫øt qu·∫£

### Model Comparison (Cross-Validation)

| Model             | Test R¬≤    | Test MAE (‚Ç¨) | Test RMSE (‚Ç¨) | Fit Time (s) |
| ----------------- | ---------- | ------------ | ------------- | ------------ |
| Random Forest     | 0.8772     | 903.5        | 1367.7        | 25.9         |
| XGBoost           | 0.8859     | 882.3        | 1321.4        | 0.11         |
| Gradient Boosting | 0.8473     | 1040.0       | 1528.5        | 26.5         |
| KNN               | 0.8530     | 992.3        | 1499.6        | 0.43         |
| Linear Regression | 0.7150     | 1554.9       | 2088.2        | 0.6          |
| Decision Tree     | 0.8264     | 1039.6       | 1629.5        | 1.08         |

_L∆∞u √Ω: K·∫øt qu·∫£ c√≥ th·ªÉ kh√°c nhau t√πy thu·ªôc v√†o preprocessing v√† tuning_

### Best Model Performance

**Random Forest (After Tuning):**

- ‚úÖ R¬≤ Score: **0.8831**
- ‚úÖ MAE: **882.3**
- ‚úÖ RMSE: **1331.6**

**√ù nghƒ©a:**

- M√¥ h√¨nh gi·∫£i th√≠ch ƒë∆∞·ª£c **88.31%** s·ª± bi·∫øn thi√™n c·ªßa gi√° xe
- Sai s·ªë trung b√¨nh kho·∫£ng **882.3‚Ç¨** (kh√° t·ªët cho d·ªØ li·ªáu xe c≈©)

---

## üõ†Ô∏è C√¥ng ngh·ªá s·ª≠ d·ª•ng

### Machine Learning

- **scikit-learn**: Pipeline, ColumnTransformer, Cross-Validation
- **XGBoost**: Gradient Boosting implementation
- **category_encoders**: Target Encoding cho high cardinality

### Data Processing

- **pandas**: Data manipulation
- **numpy**: Numerical computing

### Visualization

- **matplotlib**: Static plots
- **seaborn**: Statistical visualization
- **ydata-profiling**: Automated EDA reports

### Environment

- **Jupyter Notebook**: Interactive development
- **tqdm**: Progress tracking
- **conda/pip**: Package management

---

## ‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng

### 1. V·ªÅ Data Leakage

```python
# ‚ùå WRONG: Fit tr√™n to√†n b·ªô dataset tr∆∞·ªõc khi split
preprocessor.fit(X)
X_train, X_test = train_test_split(X)

# ‚úÖ CORRECT: Fit ch·ªâ tr√™n training set
X_train, X_test = train_test_split(X)
preprocessor.fit(X_train)
```

### 2. V·ªÅ Cross-Validation

- **Ch·ªâ s·ª≠ d·ª•ng training data** cho CV
- Kh√¥ng bao gi·ªù d√πng test set trong CV
- Final evaluation lu√¥n tr√™n holdout test set

### 3. V·ªÅ Memory & Performance

```python
# T·ªëi ∆∞u h√≥a memory cho dataset l·ªõn:
df = pd.read_csv('data/autos.csv',
                 dtype={'postalCode': 'int32', 'powerPS': 'int16'})

# S·ª≠ d·ª•ng parallel processing:
model = RandomForestRegressor(n_jobs=-1)  # D√πng t·∫•t c·∫£ CPU cores
```

### 4. V·ªÅ Target Encoding

- **Ch·ªâ d√πng cho high cardinality** (brand, model)
- C√≥ th·ªÉ g√¢y overfitting n·∫øu l·∫°m d·ª•ng
- Lu√¥n k·∫øt h·ª£p v·ªõi regularization

### 5. V·ªÅ Profiling Report

```python
# ydata_profiling c√≥ th·ªÉ r·∫•t ch·∫≠m v·ªõi dataset l·ªõn
# N·∫øu qu√° l√¢u, c√≥ th·ªÉ gi·∫£m k√≠ch th∆∞·ªõc m·∫´u:
sample_df = df.sample(n=50000, random_state=42)
profile = ydata_profiling.ProfileReport(sample_df)
```

### 6. Th·ª© t·ª± ch·∫°y code

‚ö†Ô∏è **B·∫ÆT BU·ªòC ch·∫°y tu·∫ßn t·ª± t·ª´ tr√™n xu·ªëng d∆∞·ªõi**

- Kh√¥ng skip c√°c cell preprocessing
- Kh√¥ng ch·∫°y l·∫°i cell train m√† ch∆∞a reset kernel
- N·∫øu g·∫∑p l·ªói, restart kernel v√† ch·∫°y l·∫°i t·ª´ ƒë·∫ßu

### 7. Troubleshooting

#### L·ªói: `ModuleNotFoundError: No module named 'ydata_profiling'`

```bash
pip install ydata-profiling
# ho·∫∑c
conda install -c conda-forge ydata-profiling
```

#### L·ªói: `MemoryError` khi ch·∫°y profiling

```python
# Gi·∫£m s·ªë l∆∞·ª£ng m·∫´u ho·∫∑c t·∫Øt m·ªôt s·ªë features:
profile = ydata_profiling.ProfileReport(
    df,
    minimal=True,  # Ch·∫ø ƒë·ªô t·ªëi gi·∫£n
    explorative=False
)
```

#### L·ªói: Cross-validation qu√° ch·∫≠m

```python
# Gi·∫£m n_splits ho·∫∑c gi·∫£m k√≠ch th∆∞·ªõc dataset:
N_SPLITS = 3  # Thay v√¨ 5
# ho·∫∑c
X_sample, y_sample = X.sample(n=100000), y.sample(n=100000)
```

---

## üìö T√†i li·ªáu tham kh·∫£o

- [scikit-learn Documentation](https://scikit-learn.org/stable/documentation.html)
- [XGBoost Documentation](https://xgboost.readthedocs.io/)
- [Target Encoding](https://contrib.scikit-learn.org/category_encoders/targetencoder.html)
- [Cross-Validation Best Practices](https://scikit-learn.org/stable/modules/cross_validation.html)
- [Feature Engineering Guide](https://www.kaggle.com/learn/feature-engineering)

---

## üë®‚Äçüíª T√°c gi·∫£: Nguy·ªÖn Minh Kh√°nh - 2311518

**T√™n d·ª± √°n**: German Used Car Price Prediction  
**M·ª•c ƒë√≠ch**: H·ªçc t·∫≠p v√† nghi√™n c·ª©u Machine Learning  
**NƒÉm th·ª±c hi·ªán**: 2025


